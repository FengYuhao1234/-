[
    {
        "id": 8,
        "studentName": "张三",
        "studentId": "student1",
        "fileName": "æ°å»º.pdf",
        "fileUrl": "/uploads/1737425059944-æ°å»º.pdf",
        "submitTime": "2025/1/21 10:04:20",
        "status": "待批改",
        "text": "\n\n山西省新型冠状病毒肺炎疫情防控\n工作领导小组办公室医疗救治组 \n \n关于抽调医疗资源支援大同市疫情防控工作的函 \n省人民医院、省儿童医院: \n根据当前大同市新冠肺炎疫情防控形势,按照省疫情防控办要求，\n抽调3名疾控专家支持大同市疫情流调工作。请省人民医院抽调2名\n院感专家指导大同市院感防控工作。请省儿童医院抽调1名儿科医师\n赴大同市第三人民医院指导医疗救治工作。 \n请大同市疫情防控办做好支援医护人员生活后勤等保障工作。支\n援医护人员工作期间要做好全程防护，支援任务结束后按照大同市疫\n情防控办研判要求，做好后续健康监测工作。 \n联系人:冀晓鹏 \n电  话:0351-3580457 \n \n10 \n20 "
    },
    {
        "id": 9,
        "studentName": "张三",
        "studentId": "student1",
        "fileName": "å¼é¢æ¥åââå¯æ±æ¾.pdf",
        "fileUrl": "/uploads/1740569063928-å¼é¢æ¥åââå¯æ±æ¾.pdf",
        "submitTime": "2025/2/26 19:24:24",
        "status": "待批改",
        "text": "\n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n1 \n题 目： 基于大语言模型的“信管研究方法论”课程阅卷系统开发                                     \n学院：  【威海】经济管理学院         专业： 信息管理与信息系统   \n学生姓名： 冯昱澔                         学号：  21711087  \n文献综述： \n1.研究背景 \n在“信管研究方法论”课程日常教学中，教师每周都需要批阅大约180道作业主观\n题。虽然部分答对即可给予满分，但是，仍然给教师带来了巨大的工作量压力。其次，\n由于学生在答题时使用不同的表述方式，既使表达相同的概念，也可能采用不同的近义\n词或句式，使得教师在批阅过程中需要反复比对和理解，增加了批阅时间。另外，人工\n批阅的重复性和高强度容易导致教师疲劳，从而影响评分的一致性和公平性。特别是在\n短时间内完成大量批阅任务时，教师难以保证所有答案都得到细致、公正的评价，同时\n也难以及时向学生提供有效反馈，影响了学习的效果和教学的质量。 \n实践表明，大语言模型（LLM: Large Language Model）可以快速提取主观题答案中\n的核心信息并进行评分，从而显著降低教师的阅卷负担，提高阅卷效率\n[1]\n。虽然人工阅\n卷仍在准确性和理解力上具有不可替代的优势，但LLM的引入可以帮助教师快速完成\n初步评阅，同时加快反馈速度，使学生能够更快地了解自己的学习情况，及时调整学习\n策略。因此，在“信管研究方法论”课程中引入LLM进行自动阅卷成为解决上述问题\n的可行解决方案\n[2]\n。 \n2.国内外研究现状 \n2.1 基于LMM的阅卷系统开发流程 \n当下主流的自动阅卷系统开发方法主要分为以下步骤：需求分析，评分机制分析，\n系统设计和系统实现。 \n2.1.1 需求分析与评分机制分析 \n学者们普遍认为，自动阅卷系统的需求包括准确性、效率和适应性。何曙光在其研\n究中提到，教育科研课题的成果转化需要注重实践应用和科研之间的互动，这为需求分\n析提供了理论依据\n[3]\n。特别是在自动阅卷系统中，系统需要根据不同类型的评价任务，\n灵活调整阅卷标准和评分方法。在这一过程中，研究者们通过分析实际应用场景，逐步\n明确了系统必须具备的功能需求和技术需求\n[4]\n。 \n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n2 \n在评分机制分析阶段，研究者们对不同评分模型进行了深入分析，探讨了如何优化\n评分的标准与算法。邓明明在其研究中提出，深度学习技术的引入大大提升了评分模型\n的准确性和可解释性，尤其是在主观题评分的过程中\n[5]\n。这些分析为自动阅卷系统提供\n了科学的评分机制，并推动了系统从传统特征提取方法向深度学习模型的转型。此外，\n孙社兵也通过对深度学习方法的探讨，进一步推动了阅卷机制的创新，使得阅卷不仅仅\n依赖传统规则，而是结合了机器学习模型的强大计算能力\n[6]\n。 \n2.1.2 系统设计 \n近年来，研究者们围绕基于LLM的自动阅卷系统展开了深入研究，聚焦于系统功能、\n数据结构和流程优化等方面。李渝翔等人构建了一套自动阅卷系统，明确了系统中的核\n心角色及其交互方式，其中教师负责录入试题、设定评分标准并审核系统评分，学生提\n交答案并获取反馈，而系统则承担答案解析、评分计算和结果存储的任务\n[7]\n。郭新顺等\n人在此基础上优化了系统的结构设计，定义了用户管理、试卷管理、阅卷引擎和数据库\n等关键模块，并采用关系型数据库存储结构化数据，同时利用非关系型数据库管理评分\n日志和答案文本，以提升系统的数据管理能力\n[8]\n。刘宇君进一步提升了阅卷引擎的智能\n化水平，基于大语言模型进行评分计算，并通过独立的评分模块与数据存储、前端交互\n等组件协同工作，使系统在扩展性和维护性方面得到优化\n[9]\n。黄裕等  人对阅卷流程进行\n了细化，构建了一整套评分逻辑，涵盖学生答案提交、系统调用大语言模型进行评分、\n教师审核评分结果以及最终存储评分数据等环节，同时确保各环节之间的信息流转顺\n畅，从而提升阅卷效率和评分一致性\n[10]\n。绫针对评分标准的不稳定性问题，引入了答案\n比对机制，使大语言模型能够生成多样化的标准答案，并通过相似度计算优化评分方法，\n以减少因学生表述方式不同而导致的不公平评分\n[2]\n。李磊等人则聚焦于评分结果的可解\n释性，构建了评分调整与反馈机制，使教师能够追踪评分依据并根据需要进行人工干预，\n确保评分更加透明和可控\n[11]\n。对于微服务架构优化系统设计，将大语言模型评分引擎作\n为独立模块，使系统能够适应不同课程的阅卷需求，提高灵活性和可扩展性\n[12]\n。综合来\n看，现有研究围绕系统架构、数据管理、评分逻辑和可解释性等方面展开，使得大语言\n模型在自动阅卷领域的应用更加完善，有效提高了阅卷效率，减少了教师的阅卷负担，\n并优化了评分的公平性和一致性。 \n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n3 \n其中,最值得注意的是2025年在CCF(中国计算机学会)上发布的《基于大模型的智\n能系统：架构及应用》。下图描述了如何结合实际场景个性化的部署大语言模型，尤其\n是如何结合知识图谱来部署个性化的大语言模型。 \n该流程图描述了基于大模型和知识图谱的问答系统工作机制。用户输入后，大模型\n首先进行向量检索，以获取相关实体、关系、属性和模式信息，并生成查询提示。同时，\n系统基于查询语句样本和知识图谱模式，利用大模型生成查询语句。查询语句随后被发\n送至图数据库进行检索，若查询成功，系统返回查询结果，并通过大模型进行知识确认\n后生成自然语言答案。若查询失败，系统会调用大模型进行查询语句纠错，并重新尝试\n查询，直到最终获取有效结果。该系统通过多轮交互和知识确认机制，确保问答的准确\n性和鲁棒性。\n \n在计算机顶刊ICLR上刊登的文章《OWL: A Large Language Model for IT Operations》\n为自动评分系统的设计提供了重要的启示\n[13]\n。在数据生成阶段，模型通过从现有文献综\n述样本中构建一个类似于Owl-Instruct的数据集，并结合质量标准进行训练，从而有效\n地涵盖了文献综述任务的不同评分维度。通过单轮与多轮对话的设计，系统能够分别处\n理单段回答的评分和整个文章结构的评估，这与文献综述的自动评分需求高度契合。同\n时，数据的生成不仅依赖人工标注，还结合了高质量的自动化筛选手段，这对于提升评\n分效率和准确性具有重要意义。 \n \n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n4 \n \n \n \n \n \n \n \n \n \n \n此外，图“Four phases of constructing Owl-Instruct and how we train our OWL\n”\n中的监督微调步骤强调了模型在特定任务上的定制化优化，这为评分系统的进一步提升\n提供了指导。通过结合\nGPT-4筛选与手动验证的双重机制，模型能够在初步筛选后进一\n步优化评分结果，剔除不符合质量标准的内容，从而确保评分的准确性和一致性。这一\n方法不仅能有效提升自动评分系统在复杂文本处理中的表现，还能保证其对不同写作风\n格和评估维度的适应能力，从而为自动化评分提供了可行的技术路径。 \n2.1.3 系统实现 \n大语言模型的智能阅卷系统的实现是近年来教育技术研究的重要领域，其技术栈和\n开发方法得到了广泛探讨和实践。现有研究普遍采用前后端分离架构，通过结合现代前\n端框架、后端服务、自然语言处理技术以及深度学习模型，构建了高效、灵活、智能的\n系统。 \n在前端开发方面，研究者们倾向于选用 React、Vue 或 Angular 等现代化框架，这\n些框架以组件化的开发方式显著提高了复杂界面的开发效率与可维护性\n[14]\n。同时，\nHTML5 和 CSS3 的广泛应用，为用户界面的响应式设计和动态交互提供了技术保障。\n为了进一步提升代码的安全性与可维护性，TypeScript 的引入也得到了认可。动态数据\n交互方面，多数研究采用 WebSocket 技术实现实时更新功能，例如评分进度与反馈展\n示\n[15]\n。 \n后端实现集中在业务逻辑处理、评分算法执行以及数据存储管理等核心环节。\nNode.js 凭借其高并发处理能力，成为实现实时性需求场景中的主要技术栈，而\n Python \n则因其在自然语言处理和深度学习领域的丰富生态系统，常用于实现评分算法\n[16]\n。一些\n研究指出，Spring  Boot 框架因其在复杂业务场景中的高稳定性和性能表现，也被用于\n大型阅卷系统的后端开发。后端通过 RESTful API 或 GraphQL 为前端提供标准化的数\n据接口，确保了系统功能的高效集成与灵活性\n[17]\n。 \n数据库设计对于系统性能至关重要。MySQL 和 PostgreSQL 等关系型数据库被广\n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n5 \n泛应用于存储用户信息、试卷记录和评分结果等结构化数据场景。同时，Redis 等非关\n系型数据库则因其高速缓存能力，被用于存储评分模型的中间结果和高频访问数据\n[18]\n。\n数据库技术的组合应用既提升了数据访问效率，又确保了数据的完整性与一致性。 \n随着技术的不断发展，自动阅卷系统正逐步采用大语言模型，并结合知识增强\n（Knowledge-Augmented  Learning）和微调（Fine-Tuning）策略，以提升评分的精准性\n和可解释性。其中，生成式人工智能（Generative  AI）在提升阅卷智能化水平方面发挥\n了重要作用。汝鹏等人（2024）探讨了生成式人工智能在教育领域的应用，并指出，传\n统基于关键词匹配或规则引擎的阅卷方式已难以满足复杂主观题的评分需求。 \n在此背景下，自动阅卷系统的发展呈现出两个核心趋势： \n 知识增强（RAG）用于提高语义理解能力\n[19]\n \n由于 LLM 的预训练数据未必完全覆盖考试所涉及的专业知识，因此直接使用 \nLLM 进行阅卷可能会导致评分偏差。为了弥补这一不足，近年来自动阅卷系统开始采\n用检索增强生成（Retrieval-Augmented Generation, RAG）方法，即在阅卷过程中，系统\n先从课程教材、评分标准、历年标准答案中检索相关信息，再将其输入大模型，以提高\n评分的精准度和一致性。例如，当 LLM 遇到一个涉及“假设检验”的主观题时，它可\n以从数据库中检索到标准答案，并结合这些知识点进行评分，而不是仅凭自身的通用语\n料库进行推理。 \n 特定领域语料库微调（LoRA）\n[20]\n \n通用大语言模型在训练时侧重于语法、流畅性和逻辑性，但在特定学科（如“信管\n研究方法论”）的主观题评分上，其标准可能不符合教学要求。为了让LLM更好地适应\n阅卷任务，可以使用LoRA（Low-Rank  Adaptation）进行轻量化微调，即基于该课程的\n历年考试题目、教师评分样本、标准答案和反馈进行训练，使其能够准确识别评分关键\n点、专业术语和逻辑推理方式。 \n3. 当前存在的问题 \n通过实际案例可以发现，将大段文字通过自然语言处理提取所得到的特征，通过卷\n积神经网络转化为灰度图像进行模型建立的时候可能会存在两种问题：首先是受限于神\n经网络本身的结构，无论选用任何一种激活函数（Relu，Softmax，Sigmoid等），随着\n网络深度的增加，都会出现梯度爆炸或梯度弥散现象\n[21]\n，而这也使得神经网络对于图像\n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n6 \n或语意理解无法更加深入，与此同时，随着网络深度的增加还会导致高计算成本，这些\n难点使得神经网络在自动考核系统中受限。第二个问题是语言问题，世界上任何一种语\n言都会存在不同语境，不同场景下表达意义不同的情况，而现在的大语言模型（Large \nLanguage Model, LLM）（以Chatgpt为例），是以transformer结构为基础、基于互联网可\n用数据训练的文本生成深度学习模型。模型是以自回归为技术实现的，意味着模型一次\n生成一个词，其中每个词都以前面的词为条件，而这就赋予了大模型在任务之中理解输\n入文本并带入特定语境下进行语义理解的能力。 \n所谓语言模型，就是让机器学会“说人话”\n[22]\n。给定一个问题，将文本进行分词，\n就形成了词序列。在w1,w2,...,wi-1序列的基础上，wi出现的概率应尽量与预训练语料\n的概率相同，即“和大部分人说的话一样”。因此基于语言模型的对话机器人，其目标\n就是“像人”，而不考虑逻辑是否正确，例如你问一道数学题，他回答“哈哈哈，好难\n的题”，本质上也是一句符合语言模型的回答。 \n因此，当前的大语言模型（如 GPT-4、Claude、Gemini）主要是基于大规模通用文\n本进行预训练，这些文本通常包括网络文章、百科、学术论文等。在阅卷任务中，模型\n需要具备对特定考试评分标准、专业知识和答案格式的理解，而这恰恰是 LLM 天然缺\n乏的部分，即对于特定场景下的自然语言生成。通过对大语言模型的使用，可以发现市\n面上常见的大语言模型主要会出现对标准答案的认知缺乏约束，评分标准可能与教师要\n求不一致，缺乏对特定术语和学科概念的理解这三方面问题。 \n为了弥补LLM 在阅卷任务中的知识局限性，可以采用检索增强生成\n（Retrieval-Augmented  Generation,  RAG）技术\n[23]\n。RAG技术的核心思想是通过结合外\n部知识库来增强大语言模型的回答能力。在阅卷任务中，RAG可以通过检索与问题相\n关的资料，帮助模型补充其在某些特定领域知识上的不足，尤其是对于那些具有专业性\n或学科特定背景的题目。通过检索相关的文本数据，RAG使得大语言模型能够在生成\n答案时，基于最新的、与问题内容相关的背景信息进行推理和回答，从而避免出现因模\n型知识库不完全或训练数据偏差所导致的错误理解。比如，当学生在回答特定专业问题\n时，RAG技术可以从专业文献中提取相关信息，提供更加符合学术要求的评分依据，\n提升评分的准确性。 \n除了RAG技术的使用，Prompt工程也是优化模型在特定任务中表现的重要手段。\nPrompt工程通过设计合理的输入格式和提示语，能够有效引导LLM产生符合期望的输\n出\n[24]\n。在阅卷任务中，精心设计的Prompt可以帮助模型理解评分标准和题目要求，使\n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n7 \n其输出的评分结果更加符合教师的评价标准。通过设置清晰的指令和输入数据，Prompt\n能够引导LLM聚焦于重要信息，避免模型对不相关内容的关注，从而提升评阅结果的\n精准度。例如，教师可以设置“评分标准”作为Prompt的一部分，让模型明确在评分\n时需要考虑的因素，如逻辑性、语言表达、学科知识的掌握等。 \n然而，尽管RAG和Prompt工程能够有效增强LLM的表现，初始模型仍然可能存\n在一些不符合实际评分需求的偏差。因此，参数微调（fine-tuning）成为解决这个问题\n的必要步骤。参数微调是指在已有的预训练模型基础上，使用特定任务的数据对模型进\n行进一步训练，以使其更好地适应特定领域的应用\n[20]\n。在阅卷任务中，通过对历史评分\n数据的微调，模型能够逐步学习教师在评分过程中对不同答案的评判标准，进而提高其\n评分的准确性和一致性。微调过程中，系统通过使用过去的评分数据（包括标准答案和\n教师的评分反馈），不断调整模型的参数，使得模型能够更好地理解题目的要求，并根\n据教师的评价逻辑进行更精确的评分。 \n因此，通过结合RAG技术、Prompt工程和参数微调，自动阅卷系统可以有效解决\n当前LLM在专业性、评分一致性以及领域知识理解上的局限性。RAG技术帮助模型引\n入外部知识进行补充，Prompt工程确保模型输出符合评分标准，而参数微调则通过历史\n数据的学习，使模型能够不断优化和适应特定任务要求。通过这三种技术的协同作用，\n自动阅卷系统能够在提高评分效率的同时，确保评分的准确性和公正性，为教师减轻工\n作负担、提升教学质量提供了有力的技术支持。 \n4. 研究内容 \n本设计围绕以下几个关键内容展开： \n4.1 需求分析 \n在进行系统开发之前，首先需要明确“信管研究方法论”课程的作业主观题形式和\n阅卷标准。通过分析现有考核方式中的痛点，如时间紧、任务重，阅卷\n过程中的主观性、\n近义词处理困难等问题，评估目前阅卷标准的不足之处。基于这些问题，为系统的功能\n设计提供明确的依据和方向。将以“信管研究方法论”课程的考核形式和阅卷标准，明\n确系统应解决的核心问题和实现的目标。\n \n现有阅卷模式中，教师在评阅主观题时面临以下挑战： \n主观性和一致性问题：学生答题表述的多样性，如使用近义词表达相同概念，常导\n致阅卷过程中评分不一致的问题。这不仅增加了阅卷的时间成本，也影响了评分的公平\n性； 逻辑错误的评估困难：学生回答中逻辑不清或论述不连贯的现象较为常见，人工评\n阅时需要花费大量精力进行推敲和判定，这对阅卷人的专业素养和耐心提出了较高要\n求； 高强度阅卷的效率问题：思考题通常涉及大批量的文本作业\n，人工阅卷工作量巨大，\n容易因阅卷疲劳导致判断偏差，影响最终评估结果的准确性。 \n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n8 \n因此基于上述分析，系统需求集中于以下三个方面： \n系统需要精准识别学生答案中使用的同义词或近义词，确保表达多样性不影响评\n分，同时具备基本的逻辑分析能力，能够检测答案中的因果关系和论述连贯性，并根据\n逻辑清晰程度给予合理评分。此外，通过自动化阅卷流程，减少人工干预，不仅能够提\n高阅卷效率，还能确保在大批量试卷中评分标准的一致性，从而实现高效且公正的自动\n评分系统。 \n因此针对于以上所述的内容，根据教师与学生的需求做出用况图。系统用户分为三\n类：教师，学生以及系统管理员。教师可以进行评分，支持手动评分和大模型评分，并\n可自定义评分标准，如设置关键词和标准答案，同时能够查看评分结果，包括历史记录\n和统计分析。学生可以提交作答结果，支持上传PDF附件和附言，并在评分完成后查\n看详细结果，包括评分和评语。系统管理员负责管理学生和教师账户，支持增删改查，\n同时进行系统维护，如数据清洗、数据备份和系统更新，其中数据备份包括答案和结果\n的存储，此外，管理员还可进行大模型更新，以确保阅卷系统的持续优化和升级。\n \n \n教师\n自定义评分标准\n评分\n查看评分结果\n设置关键词\n设置标准答案\n手动评分\n大模型评分\n保存\n查看历史记录\n结果统计分析\n泛化关系\n<<include>>\n<<include>>\n<<extend>>\n<<extend>>\n<<extend>>\n<<extend>>\n学生\n提交作答结果\n查看结果\n提交pdf附件\n提交附言\n查看评分\n查看评语\n确认提交\n<<include>>\n<<include>>\n<<extend>>\n<<extend>>\n<<extend>>\n<<extend>>\n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n9 \n从活动顺序上来看，流程从学生登录系统开始，若登录成功，学生可以上传试卷，\n之后教师登录系统进行阅卷。阅卷方式包括手动阅卷和自动阅卷，若选择自动阅卷，则\n系统使用大模型进行评分；若选择手动阅卷，则教师自行评分。评分完成后，结果被保\n存并上传，学生随后可以查看评分与评语。如果学生对评分结果存在疑问，可以进一步\n处理，否则流程结束。该活动图清晰展示了系统在自动化评卷和人工干预之间的流程分\n支，提高了阅卷效率和交互性。 \n系统管理员\n（Admin）\n管理账户\n管理学生账户\n管理教师账户\n增删查改\n<<include>>\n<<include>>\n<<extend>>\n<<extend>>\n系统维护\n系统更新\n数据清洗\n数据备份\n答案备份\n结果备份\n<<include>>\n<<include>>\n<<extend>>\n<<extend>>\n<<extend>>\n大模型更新\n<<extend>>\n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n10 \n \n4.2 系统设计 \n 对于整个系统而言，系统架构围绕自动化试卷批阅与分析构建，采用分层设计确保\n高效的数据处理与业务执行。前端服务提供试卷上传、手工批阅、自动批阅和统计分析\n功能，便于用户交互；接口层通过大模型调用接口、数据分析接口和业务数据接口，实\n现与AI模型及外部系统的交互；业务层涵盖文件识别与验证、文字识别、表格及公式\n识别等核心功能，确保试卷内容的精准解析与处理；数据层存储教师数据、学生数据、\n考试数据、标准答案及学生试卷等关键信息，为自动化批阅提供数据支持；基础服务包\n括数据库与知识库、对象存储及平台UI/UX，保障系统的稳定运行；运行环境支持本地\n大模型或平台部署，以满足数据安全和性能优化需求。 \n在大模型阅卷模块首先采用了基于RAG（Retrieval-Augmented  Generation）技术的\n大语言模型（LLM）进行自动阅卷，用来在提升教师批阅主观题作业的效率与准确性，\n减少大模型的“幻觉”现象。首先，系统从种子数据开始，通过RAG技术将这些数据\n转化为一个语料库。\nRAG技术通过从外部数据库中检索相关信息，并结合已有的知识\n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n11 \n生成新的文本，从而增强了模型对问题背景的理解能力和答题内容的处理精度。该语料\n库作为向量集，与此同时通过prompt 工程将评分标准（Quality Criteria）与学生答题数\n据（Input Data）一起提供给LLM进行评阅。 \n在评阅过程中，LLM根据预设的评分标准和输入数据，对学生的答案进行分析，\n生成评分结果。评分结果采用标准化的类格式输出，其中包括分数（Score）和评语\n（Reason）。评语不仅说明了学生答案的优缺点，还可以指出学生在答题时是否准确使\n用了关键词或表达了核心概念。尽管LLM能够自动生成初步的评分和反馈，但为了保\n证评分的一致性和准确性，系统引入了人工验证环节。系统需要通过回顾和对比已评阅\n过的历史答案，利用这些已验证的思考题来对模型进行微调，从而提升评分的准确度和\n适用性。 \n在完成自动评阅和手动验证后，系统还将进行持续的监控与微调。根据实际的准确\n率对模型进行调整，确保系统在实际使用中的有效性和稳定性。通过这种动态的反馈机\n制，系统能够不断优化其评分标准，提高评分的一致性和公正性。整体而言，该自动阅\n卷系统融合了自动化处理与人工干预的优势，既提高了阅卷效率，又确保了评分结果的\n公正与准确，为教师减轻了阅卷负担，提升了教学质量。 \n以下为大模型内部设计模型图 \n从实现的结束细节来看，在步骤1：语料生成，为了解决大模型的可控性低与幻觉\n现象，将会使用基于检索的增强生成技术（Retrieval  Augmented  Generation,  RAG）。提\n取“信管研究方法论”课程之中的知识点为结构化或非结构化的文档，在评阅过程中，\n通过Embedding等各种各样的检索方式，从知识库中将相关内容找回，通过优先级重排\n来增强其生成与评分的准确性。 \n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n12 \n \n在步骤二中，系统通过Prompt工程对大语言模型进行细致的调整，以确保其输出\n符合预期的评分标准。在LLM任务中，Prompt工程起着至关重要的作用，它通过为模\n型提供明确且清晰的指令，帮助模型生成符合教师评分要求的输出。在设计Prompt\n时，\n需要考虑评分的关键标准，如“逻辑性”、“语言表达清晰度”和“知识点掌握”等，确\n保模型能够准确地聚焦在这些重要的评判维度上。为了使评分结果更加精确，Prompt\n设计还需要包括评分细则，明确在答题过程中哪些内容应获得高分，哪些内容则应受到\n扣分。例如，表达清晰度和逻辑性各自占有一定的分数比例，系统会依据这些标准对答\n案进行详细评分。通过这种方式，Prompt工程能够有效引导LLM生成符合教师期望的评\n分和反馈，输出的结果以标准化的类格式展现，如“\nScore: 80, Reason: The Answer doesn’t \nmatch  the  key  words  ‘Sustainable’”，这样的结构化输出既提高了评分效率，又使评分标\n准与教师要求保持一致。 \n尽管通过Prompt工程能够有效优化模型的评分表现，但LLM仍可能在理解某些专\n业术语或复杂评分规则时出现偏差。因此，参数微调（Fine-tuning）成为进一步优化模\n型的必要步骤。参数微调是在预训练模型的基础上，结合特定领域的数据进行再训练，\n从而调整模型的参数，使其更适应具体的任务要求。在阅卷系统中，微调的训练数据通\n常包括历史评分数据和教师反馈，这些数据可以帮助模型更好地理解评分的标准和规\n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n13 \n则。通 过对这些数据的学习，模型能够逐步调整其评分逻辑，提升评分的准确性和一致\n性。 \n4.3 系统实现 \n在系统设计的基础上，进行系统的实际实现。此阶段涉及编写代码、搭建数据库以\n及实现前后端功能。系统需要能够根据设计要求快速处理学生的答题数据，通过自然语\n言处理算法和大语言模型实现自动阅卷，并反馈阅卷结果。系统的实现需要保证运行效\n率、稳定性以及阅卷结果的准确性。 \n为了提高阅卷的精准度和模型的适应性，基于现有的大语言模型（如GPT、百度智\n能云大模型等）进行适配与优化。通过结合信管专业课程的特点和教学内容，对模型进\n行语料库扩充和微调，使其能够更好地理解和评估学生提交的主观性答案，尤其是在近\n义词处理、逻辑判断和语义理解等方面进行优化。 \n与此同时，为了确保自动阅卷系统的高效开发和稳定运行，开发环境的配置从硬件、\n操作系统、开发工具和依赖库等多个方面进行了详细规划：  \n处理器 (CPU): Intel Core i7 \n内存 (RAM): 16GB \n存储: SSD 硬盘，512GB \nGPU: NVIDIA CUDA Toolkit 11.8  \n操作系统：Windows 10 \n集成环境（IDE）：PyCharm Professional 2023.3 \n               Visual Studio Code 1.85. \n前端框架：React.js 18.2.0 \n后端框架：Flask 2.3.3，Django 4.3.2（备用） \n数据库驱动: PyMySQL 1.0.3 \n \n5. 预期成果 \n在自动阅卷系统中，课题最终成果将从以下三个方面展示： \n5.1 系统分析成果 \n在系统分析阶段，采用 UML 用例图（Use  Case  Diagram） 和 顺序图（Sequence \nDiagram） 进行建模，以明确阅卷系统的核心功能、用户交互方式及数据结构。用例图\n主要描述不同角色在系统中的操作，以清晰展现教师、学生和系统管理员的职责。教师\n可以创建考试、手动阅卷、调整评分并查看成绩，学生则负责提交答案、查看评分和反\n馈，而系统管理员负责管理用户和系统维护。通过用例图分析，我们能够直观地看到系\n统的核心功能模块，以及各类用户的交互流程，为后续的系统架构设计提供指导。 \n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n14 \n类图进一步定义了系统的数据结构，确保各功能模块能够高效协同运作。系统的核\n心类包括用户（User）、教师  （Teacher）、学生（Student）、考试（Exam）、答案（Answer）、\n评分（Grading）以及大语言模型（LLM）。教师和学生继承自用户类，分别拥有阅卷和\n提交答案的权限，考试类管理题目和答案，评分类记录自动或人工评分结果，而 LLM 负\n责解析学生答案、提供分数和生成反馈。类图不仅定义了各类对象的属性和方法，还描\n述了它们之间的关系，如评分类与答案类的关联，使得系统能够灵活处理阅卷、评分和\n反馈的全过程。 \n5.2 系统设计成果 \n从系统设计的角度来看，基于需求分析的结果，系统设计将从数据流与功能模块这\n两个层面展开： \n阅卷系统的数据流图(非结构化方法)\n应该按照：用户通过前端上传试卷文件；后端\n解析试卷内容\n并存入数据库，同时调用模型进行答案分析与评分；模型生成评分与反馈，\n结果经后端处理后存储，并推送到前端显示；教师可根据需求调整评分规则，重新分析\n数据或导出统计报告的顺序进行。\n \n针对于教师与学生的需求，系统功能模块通过以下方式进行划分： \n功能模块 功能描述 \n用户管理模块 提供教师和学生用户的注册、登录及角色权限管理功能 \n试卷管理模块 持试卷上传、下载和内容预览。提供试题与答案的批量\n录入功能 \n自动评分模块 核心模块，负责对学生提交的答案进行关键词提取、语\n义理解、逻辑结构分析及评分 \n反馈生成模块 使用大模型生成基于评分结果的详细反馈，包括内容分\n析、逻辑建议及语言表达改进 \n评价标准管理模块 支持教师自定义评分标准，包括关键词权重、逻辑关系\n分析规则及语法规范要求 \n数据分析与报告模块 生成学生成绩统计、班级平均分、评分误差等多维度数\n据分析报告 \n \n5.3 系统实现成果 \n系统采用前后端分离的分布式架构，以提高模块独立性和可扩展性。前端负责用户\n界面与交互，后端负责核心逻辑与数据处理，二者通过Html  API进行通信：在前端，\n基于 React.js 框架开发，配合 CSS/SCSS 实现界面样式，提供动态交互能力和响应式\n设计以适配不同设备。在后端，初步计划基于 Node.js（Express框架），支持I/O\n操作，\n处理评分逻辑、模型调用及数据管理。与此同时使用其他高效后端框架（如Django或\n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n15 \nFlask）。 对于数据库设计：采用关系型数据库（如MySQL或PostgreSQL）存储试卷数\n据和评分记录，同时利用非关系型数据库（如MongoDB）支持日志和模型训练数据存\n储。 \n在自动阅卷的实现过程中，引入检索增强生成（\nRetrieval-Augmented  Generation,  \nRAG） 和 LoRA（Low-Rank Adaptation） 技术，以提升模型的评分准确性和稳定性。\nRAG 通过结合外部知识检索和大语言模型生成，确保LLM在评分时能够动态引用标准\n答案、评分规则和课程教材知识，而不仅仅依赖其通用训练数据。系统在实现 RAG 机\n制时，主要采用向量数据库（如FA IS S或Milvus）进行文本嵌入存储，并使用\nEmbedding \n模型（如 BGE 或 OpenAI  Embeddings） 进行相似度计算，以检索出与当前试题相关\n的标准答案或评分指导信息。在阅卷过程中，系统会先检索与学生答案最匹配的评分参\n考资料，并将其与答案内容一起传入LLM，从而提升评分的可靠性和一致性。 \n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n16 \n研究方案 \n1.研究所用的理论基础 \n1.1 大语言模型理论 \n本研究基于大语言模型（LLM）的核心理论，包括Transformer架构、多头自注意力机 制、预\n训练与微调技术等(大语言模型)。特别是涌现能力和上下文学习能力为复杂任务求解提 供了理论支\n持。 \n1.2 模型适配与优化方法 \n 在大语言模型的基础上，本研究通过模型的适配与优化方法，结合信管专业的特点和课程 内\n容，对模型进行微调与优化，以提高模型在理解和评价学生主观性答案时的准确性与适用性。采用\n增强学习和反馈机制，进一步提升模型的阅卷标准执行能力。 \n1.3 教育评价理论 \n 借鉴教育评价理论中对有效性、公平性和反馈的要求，构建符合课程教学目标的阅卷指标和评\n价方法。 \n2.研究方法 \n2.1 文献研究法 \n 通过查阅国内外关于大语言模型及其教育应用的研究，构建系统分析、设计的理论框架。 \n2.2 实验研究法 \n 基于信管课程数据，设计实验验证系统阅卷准确性和一致性，对比人工阅卷结果。 \n2.3案例分析法 \n 选取实际考试数据作为测试案例，分析模型的阅卷表现和生成反馈的效果。 \n2.4 系统开发方法 \n 使用面向对象的开发方法，结合大语言模型优化后的能力，开发功能模块化的智能考核系统。 \n3. 研究步骤 \n研究步骤 研究内容 \n需求分析与文献综述（第\n1-2周） \n调研“信管研究方法论”课程的教学内容、考核需求以及现有的阅\n卷标准。 \n分析现有考核方式的痛点与不足，明确研究的方向和功能需求，为\n后续系统设计提供理论依据和实践目标。 \n通过文献综述，了解目前在教育评估中使用的大语言模型应用和阅\n卷机制的研究现状，构建相关的理论框架。 \n评分机制分析（第3-5基于调研结果，分析现有评分标准，设计适用于“信管研究方法论”\n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n17 \n周） 课程的评分机制，涵盖文本理解、逻辑分析、内容准确性评估、格\n式规范性检查等多个维度。 \n结合多模态数据处理和自然语言处理技术，建立评分模型的初步框\n架，为后续系统实现提供理论支持。 \n系统设计（第6-7周） 设计自动阅卷系统的整体架构，明确核心模块的功能，如数据采集、\n预处理、模型阅卷、反馈生成和数据存储等。 \n确定系统的技术栈与架构，规划前后端交互方式，确保系统模块化、\n可扩展。 \n系统实现（第8-11周） 基于设计框架，开发自动阅卷系统的核心模块，包括数据上传、自\n动阅卷 引擎与反馈生成系统。 \n在实现过程中进行阶段性测试，确保系统各个模块能够按预期进行\n数据交互和阅卷处理。 \n大模型的实现 （第12-14\n周） \n选用GPT-4或其他大语言模型，并通过指令微调（Fine-Tuning）技\n术对模型进行调整，使其适应“信管研究方法论”课程的考核场景。 \n利用人工对齐技术（如RLHF）进一步优化模型的阅卷与反馈生成能\n力，提高模型的准确性与适应性。 \n系统测试与效果评估（第\n15-16周） \n进行系统的全面测试，包括准确性、一致性和运行效率等方面的评\n估。 \n通过与人工阅卷的对比，检验自动阅卷系统的实际效果，分析系统\n在不同考核场景下的表现，提出优化方案。 \n4. 技术路线 \n4.1 数据预处理与向量化建模 \n数据预处理是保证大语言模型评分质量的基础，主要包括文本清洗、特征提取、语义向量化三部分。 \n1. 文本清洗与标准化 \n 采用 N LT K（Natural  Language  Toolkit）和 spaCy 进行分词、去停用词、文本归一化，确保不\n同表达方式的答案在评分时不受无关词干扰\n[13]\n。 \n 使用正则表达式（Regex）过滤特殊符号、无效字符，避免因数据噪声影响 LLM 的评分稳定性\n[13]\n。 \n2. Embedding 向量化（用于 RAG 检索） \n 采用 BGE（Bilingual Generative Embedding）或 OpenAI Embeddings 将标准答案、评分规则、\n历年考题转化为高维语义向量，存入向量数据库（FAISS/Milvus），为后续检索增强提供支持\n[20]\n。 \n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n18 \n 采用 TF-IDF  +  BERT  表示方法融合，确保 RAG 检索既能基于词频匹配核心关键词，又能利\n用 Transformer 模型捕捉深层语义关系\n[20]\n。 \n3. 答案向量化（用于模型评分） \n 使用 SBERT（Sentence-BERT） 计算学生答案与标准答案的语义相似度，为  LLM 评分提供初\n步参考，提高评分合理性\n[20]\n。 \n 采用 SentencePiece 分词，优化长文本处理，提高大语言模型的计算效率\n[20]\n。 \n4.2 RAG（检索增强生成）优化评分的知识匹配能力 \n为了提升 LLM 评分的准确性和一致性，系统采用 RAG（Retrieval-Augmented Generation） 方法，\n在模型评分时动态检索评分标准、相关知识点、标准答案，避免仅依赖  LLM 内部知识。 \n1. 向量检索\n[25]\n \n 采用FA I S S（Facebook  AI  Similarity  Search）进行相似度计算，确保LLM在评分时能引用与当\n前试题最匹配的答案结构  和评分规则。 \n 采用 HNSW（Hierarchical Navigable Small World）索引提高检索效率，使系统能在毫秒级时间\n内完成评分参考文档的召回。 \n2. 动态提示词工程（Prompt Engineering）\n[25]\n \n 采用Few-Shot  Prompting 技术，基于RAG检索到的评分参考文档，动态生成评分提示词，使 \nLLM 在阅卷时能根据标准答案进行合理评分，而非仅凭通用知识评分。 \n 设计评分框架提示模板，确保 LLM 在评分时关注关键词匹配、逻辑清晰度、完整性等关键因\n素，提高评分的可解释性。 \n \n4.3 LoRA微调提升 LLM 评分适应性 \n由于通用LLM无法完全适应特定学科（如“信管研究方法论”）的阅卷需求，系统采用  LoRA\n（Low-Rank Adaptation）对 LLM 进行轻量化微调，使其具备更强的学科知识理解和评分稳定性。 \n1. 构建领域微调数据集\n[20]\n \n 选取历年考试题目、教师评分样本、学生答案及评分反馈，构建专属训练语料库。 \n 采用 Data  Augmentation\n（数据增强），通过同义词替换、句式转换、答案改写生成多样化的评\n分训练数据，提高模型对不同表达方式的适应性。 \n2. 微调过程\n[20]\n \n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n19 \n 采用 LoRA + PEFT（Parameter-Efficient Fine-Tuning） 技术，只对  LLM 的注意力层（Attention \nLayers） 进行调整，而不改变模型的全局参数，使微调更加高效（参数减少  90%+，计算成本\n降低 80%）。 \n 采用 RLHF（Reinforcement  Learning  from  Human  Feedback），结合教师评分数据，让模型更贴\n近人工评分标准，减少评分偏差。 \n \n4.4 系统架构与部署 \n系统采用 前后端分离  + 本地部署 的架构，确保高效运行和扩展性。 \n1. 前端（Front-End） \n采用 React.js + Tailwind CSS，实现动态评分结果展示、反馈可视化。 \n采用 WebSocket 实现实时评分更新，提高用户体验。 \n2. 后端（Back-End） \n采用 Node.js（Express 框架） 作为 API 网关，负责用户管理、试卷存储、评分请\n求调度。 \n采用 Flask + FastAPI 作为 LLM 评分接口，支持高并发评分任务。 \n3. 数据库（Database） \n采用 MySQL/PostgreSQL 存储学生答案、评分结果，保证数据一致性。 \n采用 MongoDB 存储日志、教师反馈、模型微调数据，提高数据管理灵活性。 \n采用 FA I S S 向量数据库 作为 RAG 检索核心，提高评分参考文献召回效率。 \n4. 模型部署（LLM Deployment） \n采用本地deepseek本地大模型推理，减少评分延迟。 \n采用 Hugging  Face  Transformers  API，支持多种 LLM 模型调用（如  GPT-4、\nDeepSeek、Baichuan）。 \n5. 预期成果（效果） \n5.1 智能考核系统 \n 提供自动阅卷、个性化反馈和多模态数据支持功能，显著提升阅卷效率与质量。 \n 系统可部署于高校，实现“信管研究方法论”课程的智能化考核。 \n5.2 研究理论成果 \n 完成关于大语言模型在专业课程考核中应用的实践探索，形成具有学术价值的研究论文。 \n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n20 \n 提出结合指令微调和人工对齐的系统开发方法，为其他领域的应用提供参考。 \n6. 研究意义 \n6.1 理论意义 \n本研究基于大语言模型（LLM）的核心理论以及教育评价理论，结合信管专业课程的特点，探索大\n语言模型在智能化教育考核中的应用价值。通过模型适配与优化，提出一种融合指令微调和人类反\n馈对齐（RLHF）的系统开发方法，为大语言模型的教育应用提供了新的思路，丰富了教育技术领\n域的理论体系。同时，本研究还致力于解决主观性答案自动评价中的难点，为教育评价研究提供了\n学术参考。 \n6.2 实践意义 \n本研究设计并实现了一个功能模块化的智能考核系统，通过自动阅卷、个性化反馈和多模态数据支\n持功能，显著提升阅卷效率。该系统针对信管课程“研究方法论”进行定制化开发，并验证了其在\n准确性、一致性和适用性方面的优势。研究成果不仅为高校教育考核智能化提供了参考案例，还对\n推动大语言模型在专业教育领域的深度应用具有重要实践价值。 \n6.3 社会与技术效益 \n本研究将减轻 教师的阅卷负担，提高教育资源的利用效率，有助于促进教育考核的公平性与标准化。\n同时，智能考核系统具备广泛的适用性，可推广到其他高校和学科领域，推动教育技术的普及与发\n展。本研究进一步验证了大语言模型在教育领域的潜力，为后续研究和产业化应用提供了宝贵经验，\n具有显著的社会效益与技术价值。 \n7.论文目录： \n摘要 \nAbstract \n第一章 绪论 \n 1.1 研究背景 \n 1.2 国内外研究现状 \n 1.3 研究内容与技术路线 \n1.4 论文结构 \n第二章 基于大语言模型的阅卷系统需求分析 \n 2.1 系统建设目标 \n 2.2 系统运行流程 \n 2.3 系统功能需求 \n  2.3.1 系统管理 \n  2.3.2 用户管理 \n  2.3.3 试卷管理 \n  2.3.4 自动评分管理 \n  2.3.5 数据分析报告管理 \n第三章 基于大语言模型的阅卷系统设计 \n 3.1 体系结构设计 \n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n21 \n 3.2 总体功能设计 \n 3.3 主要功能模块设计 \n  3.3.1 大语言模型的选取 \n  3.3.2 系统管理模块设计 \n  3.3.3 用户模块设计 \n  3.3.4 试卷模块设计 \n  3.3.5 自动评分模块设计 \n第四章 基于大语言模型的阅卷系统实现与测试 \n 4.1 开发环境搭建 \n 4.2 自动评分模块的实现 \n  4.3.1 大语言模型的调试 \n  4.3.2 LangChain的回退与回调 \n  4.3.3 管理LLM的接口并解析输出 \n  4.3.4 提示词工程 \n  4.3.5 外部数据与集成向量数据库 \n  4.3.6 大模型的检索增强生成（RAG） \n4.3 其他模块的实现 \n4.4 系统测试 \n 4.4.1 测试场景 \n 4.4.2 功能测试 \n 4.4.3 测试结果 \n第五章 结论 \n5.1 总结 \n5.2 展望 \n致谢 \n参考文献 \n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n22 \n主要参考文献： \n[1] 赵月, 何锦雯, 朱申辰, 等. 大语言模型安全现状与挑战[J]. 计算机科学,  2024,  \n51(1): 68-71. \n[2] 绫波绫波零/iMark[EB/OL]. [2025-02-24]. https://gitee.com/genshin_ayanami/i-mark. \n[3] 何曙光. 教育科研课题成果转化的实践探索与思考[J]. 中国建设教育\n,  2024(2):  \n10-13. \n[4] 何文海, 孙丽丽, 王晓东. 人工智能技术在考试阅卷中的可行性研究[J]. 中国战略\n新兴产业, 2024(27): 38-40. \n[5] 邓明明. 基于深度学习的主观题自动评分方法及其可解释性研究[D/OL]. 河南财经\n政法大学, 2023[2025-02-24].  \n[6] 孙社兵. 基于深度学习的科学论证文本自动评分研究[D/OL]. 河南财经政法大学, \n2023[2025-02-24].  \n[7] 李渝翔, 杨庆昆, 张雷. 基于Office Open XML的Excel操作题自动阅卷系统的实现\n[J]. 楚雄师范学院学报, 2024, 39(3): 116-122. \n[8] 郭新顺, 杨焜. 基于实践的ERP课程考试自动阅卷设计[J]. 大学教育\n,  2013(1):  \n71-72, 78. \n[9] 刘宇君.  Excel操作题自动阅卷算法的设计与实现[J]. 电脑开发与应用,  2014,  27(7):  \n56-60. \n[10] 黄裕, 王健. Word文档自动阅卷系统分析与设计[J]. 软件导刊, 2013, 12(4): 66-67. \n[11] 李磊, 李宁, 任行学. 基于机器学习的自动阅卷关键技术研究[J]. 现代计算机, 2024, \n30(10): 76-81. \n[12] 袁园. 基于OpenAI的主观题自动评分方法的研究与应用[D/OL]. 长江大学, \n2024[2025-02-24].  \n[13]  GUO  H,  YANG  J,  LIU  J,  等.  OWL :  A  LARGE  LANGUAGE  MODEL  FOR  IT \nOPERATIONS[J]. 2024. \n[14] 宋艳, 夏通, 钱江. 面向信息系统软件开发项目的管理方法[J]. 黑龙江科技信息, \n2016(13): 160-161. \n[15] 王冬霞. 学生代码自动评分与反馈[D/OL]. 华东师范大学,   2023[2025-02-24]. \nhttps://link.cnki.net/doi/10.27149/d.cnki.ghdsu.2023.001815. \nDOI:10.27149/d.cnki.ghdsu.2023.001815. \n[16] 王冬霞. 学生代码自动评分与反馈[D/OL]. 华东师范大学, 2023[2025-02-24].  \n[17] 栾笛. 中考英文作文自动评分系统设计与实现[D/OL]. 华中科技大学, \n2021[2025-02-24].  \n[18] 唐泽恬, 张泽敏, 郝晓丽, 等. 基于机器视觉的试卷批阅系统设计与实现——图像\n处理与机器视觉课内实验案例[J/OL]. 电子制作,   2024,   32(18):   8-12+7. \nDOI:10.16589/j.cnki.cn11-3571/tn.2024.18.002. \n[19] 陈一鸣, 华烨, 沈彤, 等.  RAG架构下的跨领域知识融合方法[J]. 信息技术与信息\n化, 2024(12): 142-145. \n[20] 唐雷, 陈子逸, 梁锶翰, 等. Llama2-70b模型的微调技术及其在材料领域的应用研究\n[J]. 数据与计算发展前沿（中英文）, 2025, 7(1): 163-174. \n[21] 杨心慕. 基于深度学习的自动阅卷系统研究与实现[D/OL]. 东北师范大学\n, \n2020[2025-02-24].  \n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n23 \n[22] 徐文博, 周晓平. 类ChatGPT大语言模型在护理课程考核中的应用探索——基于\nChatGPT、文心一言、讯飞星火测试[J/OL]. 中国医学教育技术, 2024, 38(5): 567-571. \nDOI:10.13566/j.cnki.cmet.cn61-1317/g4.202405005. \n[23] 陈一鸣, 华烨, 沈彤, 等.  RAG架构下的跨领域知识融合方法[J]. 信息技术与信息\n化, 2024(12): 142-145. \n[24] 臧志栋, 汤祖懿, 秦振凯, 等. 基于关键词扩展与Prompt-BERT-RCNN模型的医疗\n问答社区短文本分类[J]. 情报科学, 2024: 1-19. \n[25] 陈一鸣, 华烨, 沈彤, 等.  RAG架构下的跨领域知识融合方法[J]. 信息技术与信息\n化, 2024(12): 142-145. \n \n毕业论文（设计）进度安排： \n序号 毕业论文（设计）各阶段内容 时间安排 备注 \n1 \n文献综述 \n第1-2周 收集相关文献与资料 \n2 \n需求分析与评分机制分析 \n第3-5周 提炼关键问题 \n3 \n系统设计 \n第6-7周 包括功能模块划分 \n4 \n系统实现 \n第8-11周 模型微调与实验验证 \n5 \n大模型适配与优化 \n第12-14周 开发前后端模块 \n6 \n系统测试与效果评估 \n第15-16周 包括准确性与稳定性 \n7 \n课题结题与答辩 \n第17-18周 根据反馈完善论文 \n\n北京交通大学毕业论文（设计）                                            开题报告 \n \n24 \n指导教师意见： \n查阅资料较全面，提出的研究方案和计划进度基本可行，内容，  行文逻辑和目录结\n构还有完善空间，同意按学生提出的计划进行。 \n \n指导教师（审核签名）：                                 审核日期：            年      月      日 "
    },
    {
        "id": 14,
        "studentName": "张三",
        "studentId": "student1",
        "fileName": "Self-thinking questions (5) - å»æé¹ 21711092.pdf",
        "fileUrl": "/uploads/1742988324039-Self-thinking questions (5) - å»æé¹ 21711092.pdf",
        "submitTime": "2025/3/26 19:25:24",
        "status": "待批改",
        "text": "\n\n Case 1: Development Research on \nChinese Culture English Blog \nCase 2: The Value of Certification \nPosition The literature review is mainly \nreflected in the second paragraph of \nthe “Introduction” section, which \nintroduces the definition of blogs \nand their characteristics, \ndemonstrates the potential of blogs \nas a communication tool, and the \nshortcomings of the existing \nresearch on the application of blogs \nin the field of Chinese culture \ndissemination. The objective of \ndeveloping an English blog system \nfor Chinese culture is to provide a \nconvenient Internet platform for \nforeigners to overcome the barriers \nof language, geography and time. \n \nLiterature review is carried out \nthroughout the introduction, which \nsystematically analyzes the \nimportance of ISNs, skill gaps, and \nindustry applications of certification \nthrough a review of existing \nliterature. A discussion of the value \nof certification leads to the research \nobjective, which is to assess the role \nand impact of certification in \npractice. The literature review \nclearly supports the formulation of \nthe research hypotheses and \nprovides a theoretical basis for the \nsubsequent analysis. \n \nContent The content is based on existing \nliterature, citing the definition of \nblogs and their application \nbackground in education, scientific \nresearch and other fields, but it is \nlimited to describing the basic \nfunctional characteristics and \npotential value of blogs, and does \nnot deal with specific case studies or \nevaluation of the effects of blogs in \ncultural communication. The \ninsufficient part of the existing \nliterature mentions that there are \nfewer applied researches in \ninternationalized communication, \nwhich indirectly echoes the research \nneeds, but fails to comprehensively \ncover the research progress in \nrelated fields. \nThe content is based on accredited \nliterature, closely related to the \nstudy title, and covers the following \nareas: \n1. the role and importance of ISN as \na modern business communication \ntool; \n2. the industry challenges posed by \nthe skilled manpower gap; \n3. certification as an important tool \nfor measuring the competence of \nISN professionals. \n \nThe importance of certification and \nits industry status is systematically \nexplained by analyzing literature \nfrom multiple fields, providing \ncomprehensive theoretical support \nfor the research hypotheses. \nMeanwhile, specific data and cases, \nsuch as hiring trends and salary \nlevels in the ISN industry, are cited \nto further enhance the \npersuasiveness of the literature \nreview. \n\nStructure Organized under clear headings, it \nconsists of three subsections: \n“Definition of Blogging”, \n“Shortcomings of Existing Research” \nand “Motivation and Value of \nCurrent Research”. In “Definition of \nBlogging”, the origin of blogging \nand its basic functions are explained \nin detail; “Shortcomings of Existing \nResearch” points out that there are \nfewer studies on the application of \nblogging in Chinese cultural \ncommunication; “Motivation and \nValue of Current Research” clarifies \nthe motivation and value of \ndeveloping the system. “Motivation \nand Value of Current Research” \nclarifies the importance and possible \ncontribution of developing the \nsystem. \nOrganized under clear headings, \nincluding “The Importance of ISN as \na Business Communication Tool,” \n“The Challenge of the Skills \nShortage,” “The Role of \nCertification,” and “The Content, \nMotivation, and Value of Current \nResearch. “Content, Motivation, and \nValue of Current Research.” Each \nsection is supported by detailed \ndiscussions and literature. For \nexample, in the “Importance of ISN \nas a Business Communication Tool” \nsection, the irreplaceability of ISN \nfor corporate communication is \nillustrated through data and case \nstudies; the “Role of Certification” \nsection analyzes the impact of \ncertification in recruitment and \ncompensation, forming the basis for \nthe study. In the section of “The \nRole of Certification”, the impact of \ncertification in recruitment and \ncompensation is analyzed, forming \na good transition from theory to \npractice. \n "
    }
]